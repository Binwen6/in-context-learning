### Mamba
##### 通过试探性实验，即使用含有三种函数类型测试点的混合数据集来训练同一个模型，我们发现：
*模型可能隐含具有对非线性结构更友好的 inductive bias，这或许导致其在处理 Gaussian 和 Dynamical 类函数时的 ICL 表现优于 Linear 函数。*

##### 以核回归（kernel regression）为例

当函数属于某个核（尤其是高斯核）再生核希尔伯特空间（RKHS），最优的点估计可写作：  
这正是 Nadaraya–Watson 核回归（或说高斯过程的后验均值解） ﹣Han et al.（2023）也从贝叶斯视角证明，在示例数足够大时，ICL 可渐近等价于核回归 

为什么Mamba 评估曲线几乎水平且误差极低？  
“一次性”闭式解：Mamba 在预训练里已经把上述核回归的计算路径“写进”了注意力权重（包括查询、键、值投影矩阵）。因此，当你添加更多 in‑context 样本时，并不会像迭代优化那样持续改进解，而是每次都“直接”给出同一个闭式解——误差自然保持平稳。  
数据无噪声、函数类匹配：如果你的测试函数恰好落在 Mamba 训练时使用的函数分布（如高斯核回归）里，在无噪声条件下，理想的核回归插值能几乎零误差地重构输出。
